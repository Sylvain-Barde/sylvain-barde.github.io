<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Fast MCS | Sylvain Barde </title> <meta name="author" content="Sylvain Barde"> <meta name="description" content="A fast Model Confidence Set algorithm"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@2.4.1/build/pseudocode.min.css" integrity="sha256-VwMV//xgBPDyRFVSOshhRhzJRDyBmIACniLPpeXNUdc=" crossorigin="anonymous"> <link rel="shortcut icon" href="/assets/img/favicon-32x32.png?8012c4a598313e83c35ce5ff01281a1b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sylvain-barde.github.io/projects/fast_mcs/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sylvain</span> Barde </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Fast MCS</h1> <p class="post-description">A fast Model Confidence Set algorithm</p> </header> <article> <h3 id="table-of-contents">Table of contents</h3> <ul> <li><a href="#overview">Overview</a></li> <li><a href="#project-contributions">Project contributions</a></li> <li><a href="#areas-of-improvement">Areas of improvement</a></li> </ul> <h3 id="overview">Overview</h3> <p>This project provides a fast updating implementation of the Model Confidence Set (MCS) algorithm <a class="citation" href="#Hansen_et_al_2011">(Hansen et al., 2011)</a>. It is actually an old project that has evolved over the years. Its origin lies in when I was working on my application of the MIC to agent-based model selection on financial markets <a class="citation" href="#barde2016direct">(Barde, 2016)</a>. Because the MIC is essentially a noisy measurement of the AIC for simulation models, one needs to account for the fact that differences in model rankings may not be statistically significant. A colleague helpfully suggested the MCS approach, which at the time was relatively new, which was helpful. However, with the 513 specifications used in the analysis, it took a <em>looooong</em> time to run, and attempts at larger collections rapidly exhausted the 8GB of RAM on my desktop (In those days, that was considered a lot).</p> <p>This prompted me to investigate the scaling characteristics of the MCS approach, and see if it was possible to improve on this. The intuition laid out below arrived quickly, but the proof of equivalence took much longer (embarrassingly so Iâ€™m afraid to say). Details of all this, in particular the proofs is provided in <a class="citation" href="#barde4907732large">(Barde, 2024)</a>. The MCS approach uses losses \(\mathcal{L}\) for a collection of \(M\) models, and iteratively identifies the worst performing model and eliminates it from the collection if the performance is significantly worse. This process continues until the null of equal predictive ability cannot be rejected for the candidate model, and the surviving models comprise the MCS. This process, referred to as the <em>elimination implementation</em>, requires an appropriate elimination statistic to identify the candidate model and a suitable bootstrap for the P-values, however it is incredibly intuitive.</p> <p>The MCS procedure requires an \(N \times M\) set of losses \(L\), in order to calculate the relative loss \(d_{i,j,n} \equiv L_{n,i} - L_{n,j}\) of model $i$ relative to model $j$. These are used to calculate the following set of t-statistics under the null hypothesis that all expected mean pairwise deviations are zero-valued, i.e. \(H_0: E[\bar d_{i,j}]=0\):</p> \[t_{i,j} = \frac{ \bar d_{i,j} }{ \hat \sigma_b \left( \delta_{i,j,b} \right)} \tag{1}\] <p>The standard deviation of the sample average \(\bar d_{i,j}\) is estimated using a bootstrap, where a set of \(N \times B\) bootstrap indices \(\mathcal{B}\) allows us to generate an \(N \times M \times B\) array of resampled loss matrices \(\mathcal{L}\). This is used to calculate resampled pairwise deviations:</p> \[\delta_{i,j,b} = \frac{1}{N} \sum_n \left( \mathcal{L} _{n,i,b} - \mathcal{L} _{n,j,b} \right) \tag{2}\] <p>Under the range (R) rule - which is the one used as the basis of the fastMCS procedure, the worst-performing model, also the candidate for elimination in any iteration, is the one having the largest pairwise t-statistic \(t_{i,j}\), i.e. the one that has the highest average normalized loss relative to any other model still in the collection.</p> <p>\begin{align} e_k = \arg \max_{i \in \mathcal{M}} \max_{j \in \mathcal{M}} \left(t_{i,j}\right) &amp; &amp; T_{e_k} = \max_{i \in \mathcal{M}} \max_{j \in \mathcal{M}}|t_{i,j}| \tag{3} \end{align}</p> <p>The distribution of this elimination statistic, which is used to test \(H_0\) against the alternate hypothesis \(H_A: E[\bar d_{i,j}] \ne 0\), is obtained using bootstrapped pairwise deviations:</p> \[\tau_{i,j,b} = \frac{ \delta_{i,j,b} - \bar d_{i,j}}{ \hat \sigma_b \left( \delta_{i,j,b} \right)} \tag{4}\] <p>These are used to generate the bootstrapped elimination statistics and associated bootstrapped p-values, where \(I(\dots)\) is the Boolean indicator function:</p> <p>\begin{align} \label{eq:p-value} \mathcal{T}_ {e_k,b} = \max_{i \in \mathcal{M}} \max_{j \in \mathcal{M}} |\tau_{i,j,b}| &amp; &amp; P_{e_k} = \max\left(P_{e_{k-1}},\frac{1}{B}\sum\nolimits_b {I\left( \mathcal{T}_ {e_k,b} \ge T_{e_k} \right)}\right) \tag{5} \end{align}</p> <p>The following algorithm summarizes the MCS iterative elimination procedure.</p> <pre><code class="language-pseudocode">\begin{algorithm}
\caption{Elimination MCS}
\begin{algorithmic}
\REQUIRE $$L$$: an $$N$$ by $$M$$ matrix of losses
\REQUIRE $$Bi$$: an $$N$$ by $$B$$ matrix of bootstrap indexes
\PROCEDURE{Eliminate}{$$L, Bi$$}
  \STATE $$t &lt;= $$ Calculate matrix of t-statistics with (1)
  \STATE $$tau &lt;= $$ Calculate matrices of bootstrapped statistics with (4)
  \FOR{$$k = 0$$ \TO $$M$$}
    \STATE $$e, T &lt;= $$ Find worst model with elimination rule (3)
    \STATE $$Tb &lt;= $$ Find bootstrapped statistics with (5)
    \STATE $$P &lt;= $$ Calculate bootstrapped p-value with (5)
    \STATE Remove row/column $$e$$ from $$t$$ and $$tau$$
  \ENDFOR
\ENDPROCEDURE
\RETURN $$T$$, $$P$$
\end{algorithmic}
\end{algorithm}
</code></pre> <p>Given a candidate collection of \(M\) models, the elimination implementation has a \(\mathcal{O}(M^3)\) time complexity and a \(\mathcal{O}(M^2)\) memory requirement. The former comes from the fact that the model will have \(\mathcal{O}(M)\) iterations, each requiring finding the maximum of an \(M \times M\) matrix. The latter comes from having to store $B$ bootstrapped versions of the original \(M \times M\) elimination statistics.</p> <p>The fastMCS updating implementation reduces this down to a \(\mathcal{O}(M^2)\) time complexity and a \(\mathcal{O}(M)\) memory requirement. This is done by flipping the processing sequence, i.e. the algorithm starts with a collection of 1 model, successively adds models (rather than removing them), updating the existing rankings and p-values. Computationally, this means that each iteration now only processes vectors, rather than matrices, which explains the reduction of all requirements (time and memory) by one polynomial order. Given a model \(m\) added to an existing collection, the vector of elimination statistics (and thererefore the elimination sequence) of the exisiting collection \(T_k\), can be updated using the following rules, where \(\mathcal{E}_ {m}^{-}\) and \(\mathcal{E}_ {m}^{+}\) denote the set of models eliminated respectively <em>before</em> and <em>after</em> \(m\):</p> \[\left\{ \begin{align} T_k &amp; = T'_ k &amp; \qquad \forall \enspace k \in \mathcal{E} \_m^+ \\ T_m &amp; = \mathop {\max }\limits_i \left( { t_{m,i} } \right) &amp; \qquad \forall \enspace i \in \mathcal{M}' \\ T_k &amp; = \max \left( {T'_ k ,t_{k,m} } \right) &amp; \qquad \forall \enspace k \in \mathcal{E} _m^- \\ \end{align} \right. \tag{6}\] <p>The bootstrapped t-statistics of the previous collection, \(\mathcal{T}'_ {k,b}\) are updated using a similar set of rules:</p> \[\left\{ \begin{align} \mathcal{T}_ {k,b} &amp; = \mathcal{T}'_ {k,b} &amp; \qquad \forall \enspace k \in \mathcal{E} \_m^+ \\ \mathcal{T}_ {m,b} &amp; = \max \left(\mathcal{T}'_ {m^+,b} \, , \, \mathop {\max }\limits_i |\tau_{m,i,b}| \right) &amp; \qquad i \in \mathcal{E} \_{m}^{+} \\ \mathcal{T}_ {k,b} &amp; = \max \left(\mathcal{T}'_ {k,b} \, , \, \mathop {\max }\limits_i |\tau_{m,i,b}| \right) \qquad \forall \enspace k \in \mathcal{E}_ m^-, i\in\mathcal{E} _k^+ \\ \end{align}\right. \tag{7}\] <p>Note the updating rules (6) can be shown to work for all models \(m\) that are not in the set of superior models \(\mathcal{M}\). The updating rules (7) only actually work under the restrictive (and unrealistic) assumptions that when a model \(m\) is added it does not disturb the rankings of worse-ranked models. Nevertheless, this is enough to establish that the updating algorithm 2 will provide identical output to the elimination algorithm 1 for all models not in the superior set \(\mathcal{M}\). Details of why this is are provided in the paper, however this provides intuition as to why a 2-pass approach is used: The first pass generates the elimination statistics, and this the model rankings. In the second pass, models are processed in reverse elimination order to obtain the p-values. Given this, the two-pass version of the fast updating algorithm is outlined below:</p> <pre><code class="language-pseudocode">\begin{algorithm}
\caption{Two-pass Fast updating MCS}
\begin{algorithmic}
\REQUIRE $$L$$: an $$N$$ by $$M$$ matrix of losses
\REQUIRE $$Bi$$: an $$N$$ by $$B$$ matrix of bootstrap indexes
\PROCEDURE{ModelRankings}{$$L$$}
  \STATE $$t &lt;= $$ Calculate vector of t-statistics with (1)
  \STATE $$T &lt;= $$ Update model rankings with (6)
\ENDPROCEDURE
\STATE $$e &lt;= $$ Sort models by ascending value of $$T$$
\PROCEDURE{Pvalues}{$$L,Bi,e$$}
  \FOR{$$i = 0$$ \TO $$M$$}
    \STATE $$m &lt;= e[i]$$
    \STATE $$tau &lt;= $$ Calculate vectors of bootstrapped statistics with (4)
    \STATE $$Tb &lt;= $$ Update bootstrapped statistics with (7)
    \STATE $$P &lt;= $$ Calculate bootstrapped p-value with (4)
  \ENDFOR
\ENDPROCEDURE
\RETURN $$T$$, $$P$$
\end{algorithmic}
\end{algorithm}
</code></pre> <p>The paper <a class="citation" href="#barde4907732large">(Barde, 2024)</a> runs a benchmarking exercise using the original Monte-Carlo testing exercise of <a class="citation" href="#Hansen_et_al_2011">(Hansen et al., 2011)</a>, the results of which are provided in the figures below.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fastMCS/benchmark_time_N_250.jpg" sizes="95vw"></source> <img src="/assets/img/fastMCS/benchmark_time_N_250.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Time benchmarking for N=250" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fastMCS/benchmark_mem_N_250.jpg" sizes="95vw"></source> <img src="/assets/img/fastMCS/benchmark_mem_N_250.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Memory benchmarking for N=250" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> These plots show the time (left plot) and memory (right plot) benchmarking exercises in log units for an empirical sample of N=250 observations. The trajectories confirm the cubic time complexity and quadratic memory requirement for the elimination algorithm. The equivalent requirements for the updating algorithm are quadratic and linear respectively. </div> <p>The two algorithms (elimination and fastMCS) are proven to provide equivalent output, however this is an â€˜almost surely as \(N \to \infty\)â€™ result. Iâ€™m not that worried, as the practical rate of convergence is likely to be very fast, as the elimination statistic is an order statistic, due to the fact we are looking at a â€˜maximumâ€™. To be safe I ran a second exercise with \(N=30\) to check for any deviations. The two algorithms still provide identical output, even for this small sample size.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fastMCS/benchmark_time_N_30.jpg" sizes="95vw"></source> <img src="/assets/img/fastMCS/benchmark_time_N_30.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Time benchmarking for N=30" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fastMCS/benchmark_mem_N_30.jpg" sizes="95vw"></source> <img src="/assets/img/fastMCS/benchmark_mem_N_30.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Memory benchmarking for N=30" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> These are equivalent benchmarking plots for the N=30 case. Crucially, even for such a small evaluation sample, in every case the model rankings and p-values outputed by the updating algorithm exactly match those of the elimination algorithm. </div> <p>The practical implication of these improved scaling characteristics are illustrated by the following table. This extrapolate the benchmarking results obtained for the elimination MCS to larger collections. The last row indicates that establishing the MCS of a collection of 10,000 models would require 579 hours (~24 days) and require 2.4 TB of RAM in doing so. The fastMCS algorithm can achieve the same task in 40 minutes with 423 MB.</p> <table> <thead> <tr> <th>Â </th> <th style="text-align: right"><strong>Elimination</strong></th> <th style="text-align: right">Â </th> <th>Â </th> <th style="text-align: right"><strong>Two-pass</strong></th> <th style="text-align: right">Â </th> </tr> </thead> <tbody> <tr> <td>Â </td> <td style="text-align: right">Time (sec)</td> <td style="text-align: right">Memory (MB)</td> <td>Â </td> <td style="text-align: right">Time (sec)</td> <td style="text-align: right">Memory (MB)</td> </tr> <tr> <td>M = 500</td> <td style="text-align: right">295</td> <td style="text-align: right">6,017</td> <td>Â </td> <td style="text-align: right">3</td> <td style="text-align: right">23</td> </tr> <tr> <td>M = 1,000</td> <td style="text-align: right">2,318</td> <td style="text-align: right">24,055</td> <td>Â </td> <td style="text-align: right">11</td> <td style="text-align: right">44</td> </tr> <tr> <td>M = 2,000</td> <td style="text-align: right">17,735</td> <td style="text-align: right">96,219</td> <td>Â </td> <td style="text-align: right">67</td> <td style="text-align: right">86</td> </tr> <tr> <td>M = 5,000</td> <td style="text-align: right">265,314</td> <td style="text-align: right">601,399</td> <td>Â </td> <td style="text-align: right">557</td> <td style="text-align: right">212</td> </tr> <tr> <td>M = 10,000</td> <td style="text-align: right">2,084,924</td> <td style="text-align: right">2,405,669</td> <td>Â </td> <td style="text-align: right">2,441</td> <td style="text-align: right">423</td> </tr> </tbody> </table> <div class="caption"> Benchmarking performance in 'human' units for collections of size M. The performance gains are huge, especially for larger collections. </div> <h3 id="project-contributions">Project contributions</h3> <h4 id="what-bits-does-this-project-reach-that-others-dont">What bits does this project reach that others donâ€™t?</h4> <ul> <li>Well, clearly, the performance gains on large collections are valuable in themselves, as it unlocks types of large-scale forecasting evaluations that were not tractable before. Combine this with todayâ€™s big data world and incentives to provide better forecasts (of financial volatility, of commodity prices, of the weather, etc.) and it is not hard to see potential benefits. Of course, most of the academic literature using the MCS tends to use small collections to test novel methods against a handful of benchmarks, in such cases the elimination MCS will be perfectly adequate.</li> <li>A second benefit, even for small comparisons, is that by updating the MCS as models are added, rather than shrinking the MCS as models are eliminated, allows for a comparison exercise to be updated <em>ex-post</em>. Suppose you have access to an HPC service and pay the cost involved in running an M=10,000 collection, as in the table above. 24 days later, you have your MCS. If at that point you realise that you forgot to include 100 models from an obscure corner of the forecasting literature, you have no choice than to re-run the whole thing. With fastMCS, you can just update your MCS with these 100 models at a fraction of the compute cost. This re-introduces the possibility of collaborative research in the spirit of <a class="citation" href="#White_2000">(White, 2000)</a>, where researchers post their model losses, bootstrap indices and MCS results (elimination statistics and P-values) so that subsequent researchers can build on them at a later date.</li> </ul> <h3 id="areas-of-improvement">Areas of improvement</h3> <h4 id="things-im-not-that-happy-about-right-now">Things Iâ€™m not that happy about right now.</h4> <ul> <li>A first consideration, as mentioned above, is that most uses of the MCS have small collections (less than 10 models), where this performance improvement will not matter. So fastMCS might not necessarily displace the elimination approach in practice. Iâ€™m fine with that personally!</li> <li>Right now, this works for the â€˜Râ€™ (range) elimination rule only. Iâ€™ve not looked at the other rule proposed by <a class="citation" href="#Hansen_et_al_2011">(Hansen et al., 2011)</a>, the â€˜maxâ€™ rule, where candidates for elimination are selected based on their deviation from average performance in the collection. So this means that fastMCS is not currently as flexible as the elimination approach. I suspect that this is harder, as the average needs to be re-calculated in between iterations. It should be possible to re-calculate the average and the elimination statistics of existing models when a model is added, but whether the same can be done for the bootstrapped statistics is an open question. However, this is an interesting area for other research.</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="barde4907732large" class="col-sm-8"> <div class="title">Large-Scale Model Comparison with Fast Model Confidence Sets</div> <div class="author"> <em>Sylvain Barde</em> </div> <div class="periodical"> <em>SSRN Working Paper No. 4907732</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The paper proposes a new algorithm for finding the confidence set of a collection of forecasts or prediction models. Existing numerical implementations use an elimination approach, where one starts with the full collection of models and successively eliminates the worst performing until the null of equal predictive ability is no longer rejected at a given confidence level. The intuition behind the proposed implementation lies in reversing the process, i.e. starting with a collection of two models and updating both the model rankings and p-values as models are successively added to the collection. The first benefit of this approach is a reduction of one polynomial order in both the time complexity and memory cost of finding the confidence set of a collection of M models, falling respectively from O(M^3) to O(M^2) and from O(M^2) to O(M). The second key benefit is that it allows for further models to be added at a later point in time, thus enabling collaborative efforts using the model confidence set procedure. We prove that this implementation is equivalent to the elimination approach and demonstrate the improved performance on a multivariate GARCH collection consisting of 4800 models.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="barde2016direct" class="col-sm-8"> <div class="title">Direct comparison of agent-based models of herding in financial markets</div> <div class="author"> <em>Sylvain Barde</em> </div> <div class="periodical"> <em>Journal of Economic Dynamics and Control</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The present paper tests a new model comparison methodology by comparing multiple calibrations of three agent-based models of financial markets on the daily returns of 24 stock market indices and exchange rate series. The models chosen for this empirical application are the herding model of Gilli and Winker (2003), its asymmetric version by Alfarano et al. (2005) and the more recent model by Franke and Westerhoff (2011), which all share a common lineage to the herding model introduced by Kirman (1993). In addition, standard ARCH processes are included for each financial series to provide a benchmark for the explanatory power of the models. The methodology provides a consistent and statistically significant ranking of the three models. More importantly, it also reveals that the best performing model, Franke and Westerhoff, is generally not distinguishable from an ARCH-type process, suggesting their explanatory power on the data is similar.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2011</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Hansen_et_al_2011" class="col-sm-8"> <div class="title">The Model Confidence Set</div> <div class="author"> Peter R. Hansen,Â Asger Lunde,Â andÂ James M. Nason </div> <div class="periodical"> <em>Econometrica</em>, 2011 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2000</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="White_2000" class="col-sm-8"> <div class="title">A Reality Check For Data Snooping</div> <div class="author"> Halbert White </div> <div class="periodical"> <em>Econometrica</em>, 2000 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2024 Sylvain Barde. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0}};</script> <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/pseudocode@2.4.1/build/pseudocode.min.js" integrity="sha256-aVkDxqyzrB+ExUsOY9PdyelkDhn/DfrjWu08aVpqNlo=" crossorigin="anonymous"></script> <script>document.addEventListener("readystatechange",()=>{"complete"===document.readyState&&document.querySelectorAll("pre>code.language-pseudocode").forEach(e=>{const t=e.textContent,d=e.parentElement.parentElement;let n=document.createElement("pre");n.classList.add("pseudocode");const o=document.createTextNode(t);n.appendChild(o),d.appendChild(n),d.removeChild(e.parentElement),pseudocode.renderElement(n)})});</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"Here are my main publications",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"Here is a collection of the various coding projects that might be helpful to others.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"The main elements of my curriculum vitae are provided below. A more complete PDF version is available for download.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-teaching",title:"teaching",description:"This section contains information about the courses I teach.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"news-after-several-years-of-procrastination-following-the-closure-of-my-previous-webpage-i-have-finally-bitten-the-bullet-and-decided-that-a-new-webpage-is-needed-i-ve-spent-two-spare-days-during-some-traveling-to-set-up-a-github-pages-site-with-a-the-lovely-al-folio-jekyll-template-right-now-there-isn-t-much-beyond-the-basic-functionality-but-i-ll-be-adding-more-content-including-some-more-practical-useful-material-relating-to-the-various-code-repos-i-ve-generated-over-the-years",title:"After several years of procrastination following the closure of my previous webpage, I...",description:"",section:"News"},{id:"news-progress-continues-the-cv-and-publication-sections-are-essentially-complete-what-remains-are-the-teaching-and-project-sections-which-are-still-the-boilerplate-template-but-this-will-require-a-little-more-time-to-do-properly",title:"Progress continues, the CV and publication sections are essentially complete. What remains are...",description:"",section:"News"},{id:"news-a-basic-teaching-section-is-now-available-listing-my-current-teaching-duties-at-the-university-of-kent-i-m-still-working-towards-the-final-product-which-will-involve-dedicated-pages-for-each-module",title:"A basic teaching section is now available, listing my current teaching duties at...",description:"",section:"News"},{id:"news-the-working-paper-moran-s-i-lasso-for-models-with-spatially-correlated-data-which-is-joint-work-with-guy-tchuente-and-our-former-phd-student-rowan-cherodian-has-been-accepted-for-publication-in-the-econometrics-journal-as-the-actual-citation-information-is-available-i-ll-update-the-publication-list",title:"The working paper \u201cMoran\u2019s I Lasso for models with spatially correlated data\u201d, which...",description:"",section:"News"},{id:"projects-begrs",title:"BEGRS",description:"Bayesian Estimation with Gaussian Process Regression Surrogates",section:"Projects",handler:()=>{window.location.href="/projects/begrs/"}},{id:"projects-fast-mcs",title:"Fast MCS",description:"A fast Model Confidence Set algorithm",section:"Projects",handler:()=>{window.location.href="/projects/fast_mcs/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73.%62%61%72%64%65@%6B%65%6E%74.%61%63.%75%6B","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-1465-8236","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=8-EcldIAAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Sylvain-Barde/","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Sylvain-Barde","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>